### Life Of Extremophiles Acidic

This document provides an overview of the workflows for processing and analyzing data related to PubMed articles, chemicals, and interactions.

## Task1. Handling `PMCID` Values

**File:** `final_result_GENES.csv`

**Description:**

- This task involves removing the 'PMC' prefix from the `PMCID` column in the dataset to standardize the identifier format.
- The cleaned data is saved as `Genes_RemovedPMD.csv`.

## Task2. Mapping PMIDs to PMCIDs

**File:** `Task3_Species_Acidic.csv`

**Description:**

- This step creates a mapping between `PMID` and `PMCID` by matching entries from `final_result_GENES.csv`.
- The result is saved in `check.csv`, which includes `PMID` and its corresponding `PMCID`.

## Task3. Incorporating Additional Data

**File:** `Task3_Species_Acidic.csv`

**Description:**

- This task extends the previous mapping by including additional columns from `Task3_Species_Acidic.csv`.
- The combined dataset is saved as `final_result_species.csv`, which incorporates extra information alongside the `PMID` and `PMCID` mapping.

## Task4. Extracting Sentences from PubMed

**File:** `Species_RemovedPMD.csv`

**Description:**

- This task extracts relevant sentences related to chemicals from PubMed articles using the `Give_Sentences_PMC` function.
- The sentences are collected and saved in `Species_Sentences.csv`, with each entry including details about the chemicals and the associated sentences.

## Requirements

- Ensure you have the required libraries and dependencies installed for Python and R scripts.

## How to Use

1. **Prepare Files**: Ensure that the input CSV files are located in the correct directories as specified in each script.
2. **Run Scripts**: Execute the scripts in the provided order to process the data and generate the necessary output files.
3. **Review Outputs**: Check the output files generated by the scripts to confirm that the data has been processed correctly:
   - `Genes_RemovedPMD.csv`
   - `check.csv`
   - `final_result_species.csv`
   - `Species_Sentences.csv`

## Notes

- Modify file paths in the scripts based on your environment and directory structure.
- Verify that all required libraries and tools are installed and configured correctly.

## Task5

# `find the available dataset from the internet`

## Task6

# Retrieving Protein Data from UniProt

This guide provides instructions for retrieving specific protein data from UniProt using their REST API.

## Data to Retrieve

- **Entry**: UniProt accession number of the protein.
- **Entry Name**: The unique name assigned to the protein entry.
- **Protein Names**: List of names associated with the protein.
- **Gene Names**: List of gene names related to the protein.
- **Length**: Length of the protein sequence.
- **PubMed ID**: Identifiers for publications associated with the protein.
- **GeneID**: Identifier for the gene.

## Task7

# Dataset Documentation

## Overview

This dataset includes details about various publications related to our research.

## Columns

- **Name**: The title or name of the dataset.
- **Description**: A brief summary or description of the dataset.
- **Publication Year**: The year in which the publication was released.
- **Publication Link**: The URL where the publication can be accessed.

## Purpose

This information helps in identifying and accessing relevant publications for further research and analysis.

## Task8

Identify Responsible Proteins

## Overview

The goal of this task is to identify proteins responsible for specific genes based on the dataset provided.

## Columns in the Dataset

- **Gene**: The gene of interest.
- **Protein**: The associated protein with the gene.
- **Description**: A description of the gene or protein.
- **Link**: A link to additional information or resources about the gene or protein.
- **Publication Link**: A link to the publication that provides further details or evidence about the gene-protein relationship.

## Steps

1. **Review Dataset**: Examine the dataset for entries that specify genes and their associated proteins.
2. **Verify Information**: Check the provided links and descriptions to confirm the responsible proteins.
3. **Identify Proteins**: Note the proteins listed for each gene.
4. **Document Findings**: Record the proteins responsible for each gene and link to relevant publications.

## Purpose

This process helps in understanding the role of specific proteins in relation to genes and supports further research and validation of biological functions.

## Task9

Find Chemical Drug Data

## Objective

The objective is to locate and document data related to chemical drugs, including their names, IDs, references, and trial phases.

## Data Fields

- **Chemical Name**: The name of the chemical drug.
- **Chemical ID**: The unique identifier assigned to the chemical drug.
- **Reference**: The source or reference where the chemical drug information is obtained.
- **Phase of Trial**: The phase of clinical trial (e.g., Phase I, Phase II, Phase III) in which the drug is currently or was previously involved.

## Steps

1. **Gather Data**: Collect information from reliable sources or databases about chemical drugs.
2. **Extract Information**:
   - **Chemical Name**: Record the name of each drug.
   - **Chemical ID**: Find and list the unique IDs associated with each drug.
   - **Reference**: Document the sources or references used for obtaining the data.
   - **Phase of Trial**: Identify and note the clinical trial phases for each drug.
3. **Organize Data**: Structure the data into a table or format for easy access and analysis.

## Purpose

This task aids in tracking and understanding the development status of chemical drugs, facilitating research and clinical decision-making.

## Task10

# Data Processing Scripts

This repository contains scripts for merging and processing various biological datasets. Each script merges different types of data and extracts relevant interaction types and regulations.

## Scripts Overview

### 1. **Gene_to_Chemical.py**

- **Purpose**: Merges gene and chemical data, extracts interaction types and regulations, and saves the result as `Gene_to_Chemical.csv`.
- **Key Steps**:

  ```python
  # Load DataFrames
  df1 = pd.read_csv(file1_path)
  df2 = pd.read_csv(file2_path)

  # Merge DataFrames
  merged_df = pd.merge(df1, df2, on='PMID', how='inner')

  # Define interaction and regulation keywords
  interaction_keywords = ['Inhibition', 'Activation', 'Proliferation', 'Allosteric', 'Agonist', 'Antagonist']
  regulation_keywords = ['(?:Up(?:-regulated)?)', 'Down(?:-regulated)?']

  # Process and save data
  final_df.to_csv(output_path, index=False)
  ```

### 2. **Gene_to_Disease.py**

- **Purpose**: Merges gene and disease data, extracts interaction types and regulations, and saves the result as `Gene_to_Disease.csv`.
- **Key Steps**:

  ```python
  # Load DataFrames
  df1 = pd.read_csv(file1_path)
  df2 = pd.read_csv(file2_path)

  # Merge DataFrames
  merged_df = pd.merge(df1, df2, on='PMID', how='inner')

  # Define interaction and regulation keywords
  interaction_keywords = ['Inhibition', 'Activation', 'Proliferation', 'Allosteric', 'Agonist', 'Antagonist']
  regulation_keywords = ['(?:Up(?:-regulated)?)', 'Down(?:-regulated)?']

  # Process and save data
  final_df.to_csv(output_path, index=False)
  ```

### 3. **Gene_to_Gene.py**

- **Purpose**: Merges gene data with itself, extracts interaction types and regulations, and saves the result as `Gene_to_Gene.csv`.
- **Key Steps**:

  ```python
  # Load DataFrames
  df1 = pd.read_csv(file1_path)
  df2 = pd.read_csv(file2_path)

  # Merge DataFrames
  merged_df = pd.merge(df1, df2, on='PMID', how='inner')

  # Define interaction and regulation keywords
  interaction_keywords = ['Inhibition', 'Activation', 'Proliferation', 'Allosteric', 'Agonist', 'Antagonist']
  regulation_keywords = ['(?:Up(?:-regulated)?)', 'Down(?:-regulated)?']

  # Process and save data
  final_df.to_csv(output_path, index=False)
  ```

### 4. **Chemical_to_Chemical.py**

- **Purpose**: Merges chemical data with itself, extracts interaction types and regulations, and saves the result as `Chemical_to_Chemical.csv`.
- **Key Steps**:

  ```python
  # Load DataFrames
  df1 = pd.read_csv(file1_path)
  df2 = pd.read_csv(file2_path)

  # Merge DataFrames
  merged_df = pd.merge(df1, df2, on='PMID', how='inner')

  # Define interaction and regulation keywords
  interaction_keywords = ['Inhibition', 'Activation', 'Proliferation', 'Allosteric', 'Agonist', 'Antagonist']
  regulation_keywords = ['(?:Up(?:-regulated)?)', 'Down(?:-regulated)?']

  # Process and save data
  final_df.to_csv(output_path, index=False)
  ```

### 5. **Gene_Column_Check.ipynb**

- **Purpose**: Loads gene data, checks column names, and extracts interaction types and regulations, saving the result as `Gene_to_Gene.csv`.
- **Key Steps**:

  ```python
  # Load DataFrames
  df1 = pd.read_csv(file1_path)
  df2 = pd.read_csv(file2_path)

  # Print column names
  print("Columns of df1:", df1.columns)
  print("Columns of df2:", df2.columns)

  # Define keywords
  interaction_keywords = ['Inhibition', 'Activation', 'Proliferation', 'Allosteric', 'Agonist', 'Antagonist']
  regulation_keywords = ['Up', 'Down', 'Up regulated', 'Down-regulated']

  # Process and save data
  final_df.to_csv('Gene_to_Gene.csv', index=False)
  ```

## Requirements

- `pandas`
- `tensorflow_hub`
- `numpy`
- `re`

## How to Use

1. **Place Files**: Ensure the CSV files are in the correct directories as specified in each script.
2. **Run Scripts**: Execute the corresponding Python script to process the data.
3. **Check Outputs**: The scripts will generate CSV files with the processed data in the same directory.

## Notes

- Adjust file paths in the scripts according to your environment.
- Ensure all required libraries are installed.
  '''

## Task11

````markdown
# Pathways Extraction and Analysis

This script extracts pathways information from a dataset of PubMed articles and processes it to generate a final summary CSV file.

## Requirements

- `requests`
- `beautifulsoup4`
- `pandas`

Install the required packages using:

```bash
pip install requests beautifulsoup4 pandas
```
````

## Script Overview

1. **Data Loading**

   - Reads a CSV file containing PubMed articles.
   - Loads pathway names from a text file.

2. **Fetch Full Text**

   - Extracts full text from PMC articles using their PMCID.
   - Falls back to abstracts if the full text is not available.

3. **Pathways Matching**

   - Searches for specified pathways in the full text or abstracts.
   - Stores matches in a CSV file.

4. **Data Processing**

   - Reads the CSV file of matched pathways.
   - Converts string representations of lists back to list objects.
   - Counts occurrences and identifies unique pathways.

5. **Generate Final Report**
   - Prepares a summary CSV file listing each pathway, associated PMIDs, and the count of articles for each pathway.

## Usage

1. Place your input CSV file (`Task2_pubmed_Pubtator.csv`) and text file (`pathway_names.txt`) in the `/content/` directory.
2. Run the script to process the data and generate the `virus_Pathways_20_final.csv` file.

## Outputs

- `virus_Pathways_20.csv`: Intermediate file with pathways matched to PMIDs.
- `virus_Pathways_20_final.csv`: Final summary of pathways with associated PMIDs and counts.

## Notes

- Ensure the input files are correctly formatted and placed in the specified directory.
- Adjust file paths as needed for your environment.

```


## Task12

```

# Extremophile Classification with BioBERT

## Overview

This script classifies sentences as extremophiles using a pre-trained BioBERT model. It processes text data from a CSV file in chunks, performs classification, and saves the results to a new CSV file.

## Requirements

- `pandas`
- `torch`
- `transformers`
- `random`
- `os`

## Steps

### 1. **Setup Environment**

- **Fix Random Seed**: Ensures reproducibility by setting random seeds for `torch` and `random`.
- **Suppress Warnings**: Configures environment to ignore warnings.

### 2. **Load Model and Tokenizer**

- **Model**: BioBERT (`monologg/biobert_v1.1_pubmed`)
- **Tokenizer**: For encoding sentences.

### 3. **Define Classification Function**

- **Function**: `predict_extremophiles(sentences)`
  - **Action**: Tokenizes sentences, performs inference, and classifies based on a threshold.

### 4. **Process Data**

- **File**: `Task4_Acidic_Genes_Pubmed.csv`
- **Chunk Size**: 100 rows.
- **Action**: Reads the file in chunks, predicts extremophiles, and aggregates predictions.

### 5. **Save Results**

- **Output File**: `Genes_Bacteria_results.csv`
- **Columns**: `Sentences`, `Probability`, `Verify`
- **Action**: Saves the DataFrame with predictions to the CSV file.

## Output

- **File**: `Genes_Bacteria_results.csv`
- **Contents**: Contains sentences, their extremophile probabilities, and classification results.

```

```

## Task13

```

# Sentence Summarization

## Overview

This script summarizes sentences from a CSV file using a pre-trained summarization model and saves the results to a new CSV file.

## Requirements

- `pandas`
- `csv`
- `transformers`
- `textwrap`

## Steps

### 1. **Load Data**

- **File**: `Task4_Acidic_Genes_Pubmed.csv`
- **Action**: Read the CSV file and convert to a DataFrame.

### 2. **Initialize Summarization Pipeline**

- **Model**: Pre-trained summarization pipeline from `transformers`.

### 3. **Define Functions**

- **Function**: `wrap(text)`
  - **Action**: Wraps text to fit formatting.
- **Function**: `summarize_sentence(sentence)`
  - **Action**: Summarizes each sentence and handles exceptions if no summary is generated.

### 4. **Process Data**

- **Action**:
  - Replace semicolons in the 'Sentences' column.
  - Apply the summarization function to each sentence.
- **Add Column**: `Summary` containing the generated summaries.

### 5. **Save Results**

- **Output File**: `Task13_data_with_summary.csv`
- **Action**: Save the DataFrame with the original sentences and their summaries.

## Output

- **File**: `Task13_data_with_summary.csv`
- **Contents**: Contains the original sentences and their summaries.

```

## Task14

```

# Data Aggregation from UniProt

## Overview

This script retrieves data from UniProt for a list of species and appends it to a CSV file. The data is fetched in TSV format, processed, and merged into a single CSV file.

## Requirements

- `pandas`
- `requests`
- `csv`
- `gzip`
- `io`

## Steps

### 1. **Load Data**

- **File**: `Task3_Acidic._Species_pubmed.csv`
- **Action**: Read the CSV file into a DataFrame and extract the list of species.

### 2. **Define Functions**

- **Function**: `download_and_save_tsv(url, file_path)`
  - **Action**: Downloads and saves TSV files, decompresses if necessary.
- **Function**: `append_tsv_to_csv(tsv_file_path, csv_file_path)`
  - **Action**: Appends TSV data to an existing CSV file, creating a header if the file is empty.

### 3. **Process Data**

- **Action**:
  - Iterate over the species list.
  - Construct a query URL for each species.
  - Download and save TSV data for each species.
  - Append the TSV data to a CSV file.

### 4. **Save Results**

- **File**: `merged_data.csv`
- **Action**: Save aggregated data from all species into this CSV file.

## Output

- **File**: `merged_data.csv`
- **Contents**: Merged data from UniProt for the specified species, including fields like accession, gene names, PubMed ID, and protein name.

## Notes

- Only the first 10 species are processed in this example.
- Ensure sufficient permissions for reading and writing files.

```

## Task15

```

# Chemical-Chemical Interaction Explorer

## Overview

This project visualizes chemical-to-chemical interactions in a 3D graph using Streamlit and Plotly. The graph displays interactions between chemicals, allowing users to explore relationships and interaction types.

## Workflow

### Data Loading and Preprocessing

- Load interaction data and preprocess sentences for consistency.
- Select a subset of the data for quick visualization.

### Graph Construction

- Create a directed graph using NetworkX.
- Add nodes (chemicals) and edges (interactions) to the graph.
- Store additional information about chemicals for reference.

### 3D Visualization

- Generate 3D positions for nodes using a spring layout.
- Create edge and node traces for Plotly 3D visualization.
- Define the layout and interaction types for the 3D plot.

### Streamlit Application

- Build a web interface using Streamlit for user interaction.
- Allow users to select nodes and highlight specific chemical interactions.
- Embed the Plotly 3D graph within the Streamlit app for visualization.

## Usage

1. Ensure the Python virtual environment is activated.
2. Run the Streamlit application.
3. Access the web interface to explore chemical interactions.

## Acknowledgements

This project utilizes Streamlit, Plotly, and NetworkX libraries for its functionality.

## same for Gene to Gene & Gene to Chemical interaction explorer

```

## Task16

```

# Gene-Gene Interaction Graph

## Overview

This project visualizes gene-to-gene interactions in a 2D graph using NetworkX and Plotly. The graph displays interactions between genes, allowing users to explore relationships and interaction types.

## Workflow

### Data Loading and Preprocessing

- Load interaction data from a CSV file.
- Select a subset of the data (e.g., top 300 interactions) for visualization.

### Graph Construction

- Create a directed graph using NetworkX.
- Add nodes (genes) and edges (interactions) to the graph.
- Store additional information about interactions (e.g., interaction type and regulation).

### 2D Visualization

- Generate 2D positions for nodes using a spring layout.
- Define edge colors based on interaction type.
- Create edge traces and node traces for Plotly 2D visualization.
- Customize the layout and interaction details for the plot.

### Streamlit Application (If Applicable)

- Build a web interface using Streamlit for user interaction (if implemented).
- Allow users to select nodes and highlight specific gene interactions.
- Embed the Plotly 2D graph within the Streamlit app for visualization (if applicable).

## Usage

1. Ensure the Python virtual environment is activated.
2. Run the visualization function with the appropriate file path and output path.
3. Access the generated HTML file to explore gene interactions.

## Acknowledgements

This project utilizes NetworkX and Plotly libraries for its functionality.

## Same for Gene to chemical & Chemical to Chemical

```

```

```
